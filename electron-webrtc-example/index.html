<!--
  ============================================================
  AIGuard Camera - Electron UI
   VERSION: 2.9.0 (2026-02-09)
   ============================================================
   
   CHANGELOG:
   - v2.9.0: ARCH - YAMNet loads via local HTTP server (main.js serves models)
   - v2.8.2: FIX - YAMNet model URL fallback chain (GCS direct â†’ Kaggle)
   - v2.8.1: FIX - YAMNet model URL updated from TFHub (403) to Kaggle CDN
   - v2.8.0: CRITICAL - Inline YAMNet sound detection integration (was placeholder only)
  - v2.7.0: Added sensor status indicator (camera/mic icons) in success screen
  - v2.6.0: CRITICAL FIX - Camera/Sound separation: camera only activates when motion is enabled
  - v2.5.2: Changed debounce to 60s default for security best practice
  - v2.3.2: CRITICAL FIX - Camera initialization with progressive fallbacks + clean-start sequence
  - v2.3.1: Snapshot validation for readyState/dimensions
  - v2.3.0: Added inline MediaPipe motion detection with event reporting
  - v2.2.1: Fixed monitoring initialization - proper IPC listener setup for camera start ACK
  - v2.2.0: Added renderer-monitoring.js script for motion/sound detection
  - v2.1.0: Disabled camera preflight check for Away Mode (LED fix)
  - v2.0.0: Full monitoring integration with motion/sound detection
  
  DEPENDENCIES: Electron preload.js, renderer-webrtc.js, @mediapipe/tasks-vision (CDN)
  ============================================================
-->
<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AIGuard Camera</title>
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
        background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);
        min-height: 100vh;
        display: flex;
        justify-content: center;
        align-items: center;
        color: #e2e8f0;
      }

      .container {
        background: rgba(30, 41, 59, 0.9);
        backdrop-filter: blur(10px);
        border-radius: 16px;
        padding: 40px;
        width: 420px;
        box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.5);
        border: 1px solid rgba(71, 85, 105, 0.5);
        position: relative;
      }

      .header {
        text-align: center;
        margin-bottom: 28px;
      }

      .logo {
        font-size: 48px;
        margin-bottom: 12px;
      }

      h1 {
        font-size: 24px;
        font-weight: 700;
        margin-bottom: 8px;
        color: #f1f5f9;
      }

      .subtitle {
        color: #94a3b8;
        font-size: 14px;
        line-height: 1.35;
      }

      .lang-toggle {
        position: absolute;
        top: 18px;
        right: 18px;
        display: flex;
        gap: 8px;
      }

      .lang-btn {
        padding: 8px 14px;
        border: 1px solid rgba(71, 85, 105, 0.5);
        background: rgba(30, 41, 59, 0.8);
        color: #94a3b8;
        border-radius: 10px;
        cursor: pointer;
        font-size: 13px;
        transition: all 0.2s;
        user-select: none;
      }

      .lang-btn:hover {
        background: rgba(51, 65, 85, 0.8);
        color: #e2e8f0;
      }

      .lang-btn.active {
        background: #3b82f6;
        border-color: #3b82f6;
        color: #ffffff;
      }

      .code-section {
        margin-bottom: 18px;
      }

      .code-label {
        display: block;
        margin-bottom: 12px;
        font-size: 13px;
        color: #cbd5e1;
        text-align: center;
      }

      .code-inputs {
        display: flex;
        gap: 8px;
        justify-content: center;
        margin-bottom: 14px;
      }

      .code-input {
        width: 50px;
        height: 58px;
        text-align: center;
        font-size: 24px;
        font-weight: 700;
        border: 2px solid rgba(71, 85, 105, 0.5);
        border-radius: 12px;
        background: rgba(15, 23, 42, 0.6);
        color: #f1f5f9;
        outline: none;
        transition: all 0.2s;
      }

      .code-input:focus {
        border-color: #3b82f6;
        box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.3);
      }

      .paste-btn {
        width: 100%;
        padding: 12px;
        background: rgba(51, 65, 85, 0.6);
        border: 1px solid rgba(71, 85, 105, 0.5);
        color: #94a3b8;
        border-radius: 10px;
        cursor: pointer;
        font-size: 14px;
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 8px;
        transition: all 0.2s;
        user-select: none;
      }

      .paste-btn:hover {
        background: rgba(71, 85, 105, 0.6);
        color: #e2e8f0;
      }

      .submit-btn,
      .minimize-btn {
        width: 100%;
        padding: 14px;
        background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%);
        border: none;
        color: white;
        border-radius: 12px;
        cursor: pointer;
        font-size: 16px;
        font-weight: 700;
        transition: all 0.2s;
        margin-top: 14px;
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 10px;
        user-select: none;
      }

      .submit-btn:hover:not(:disabled),
      .minimize-btn:hover {
        transform: translateY(-2px);
        box-shadow: 0 12px 22px rgba(59, 130, 246, 0.28);
      }

      .submit-btn:disabled {
        opacity: 0.5;
        cursor: not-allowed;
        transform: none;
        box-shadow: none;
      }

      .error-message {
        background: rgba(239, 68, 68, 0.18);
        border: 1px solid rgba(239, 68, 68, 0.45);
        color: #fecaca;
        padding: 12px;
        border-radius: 10px;
        text-align: center;
        margin-top: 14px;
        font-size: 14px;
        display: none;
        line-height: 1.35;
      }

      .success-screen {
        display: none;
        text-align: center;
      }

      .success-icon {
        font-size: 64px;
        margin-bottom: 12px;
      }

      .success-title {
        font-size: 24px;
        font-weight: 800;
        color: #4ade80;
        margin-bottom: 8px;
      }

      .success-subtitle {
        color: #94a3b8;
        margin-bottom: 18px;
        line-height: 1.35;
      }

      .info-box {
        background: rgba(59, 130, 246, 0.1);
        border: 1px solid rgba(59, 130, 246, 0.28);
        border-radius: 14px;
        padding: 16px;
        margin-bottom: 16px;
        text-align: start;
      }

      .info-box-title {
        font-weight: 800;
        color: #93c5fd;
        margin-bottom: 10px;
        display: flex;
        align-items: center;
        gap: 8px;
        font-size: 14px;
      }

      .info-box-text {
        color: #cbd5e1;
        font-size: 13px;
        line-height: 1.55;
      }

      .action-buttons {
        display: flex;
        flex-direction: column;
        gap: 12px;
      }

      .close-btn {
        width: 100%;
        padding: 14px;
        background: rgba(239, 68, 68, 0.18);
        border: 1px solid rgba(239, 68, 68, 0.45);
        color: #fecaca;
        border-radius: 12px;
        cursor: pointer;
        font-size: 16px;
        font-weight: 800;
        transition: all 0.2s;
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 10px;
        user-select: none;
      }

      .close-btn:hover {
        background: rgba(239, 68, 68, 0.26);
      }

      .warning-text {
        color: #fbbf24;
        font-size: 12px;
        margin-top: 6px;
        text-align: center;
        line-height: 1.35;
      }

      .hint-text {
        color: #94a3b8;
        font-size: 12px;
        margin-top: 10px;
        text-align: center;
        line-height: 1.35;
      }

      .spinner {
        width: 20px;
        height: 20px;
        border: 2px solid rgba(255, 255, 255, 0.35);
        border-radius: 50%;
        border-top-color: white;
        animation: spin 1s linear infinite;
      }

      @keyframes spin {
        to {
          transform: rotate(360deg);
        }
      }

      .live-indicator {
        display: none;
        background: rgba(239, 68, 68, 0.2);
        border: 1px solid rgba(239, 68, 68, 0.5);
        border-radius: 10px;
        padding: 12px;
        margin-bottom: 16px;
        text-align: center;
      }

      .live-indicator.active {
        display: block;
      }

      .live-dot {
        display: inline-block;
        width: 10px;
        height: 10px;
        background: #ef4444;
        border-radius: 50%;
        margin-right: 8px;
        animation: pulse 1.5s infinite;
      }

      @keyframes pulse {
        0%,
        100% {
          opacity: 1;
        }
        50% {
          opacity: 0.5;
        }
      }

      .live-text {
        color: #fecaca;
        font-weight: 700;
      }

      [dir="rtl"] .lang-toggle {
        right: auto;
        left: 18px;
      }

      [dir="rtl"] .info-box {
        text-align: right;
      }

      [dir="rtl"] .code-inputs {
        flex-direction: row-reverse;
      }

      [dir="rtl"] .info-box-title {
        flex-direction: row-reverse;
      }

      [dir="rtl"] .live-dot {
        margin-right: 0;
        margin-left: 8px;
      }

      /* Sensor status indicator */
      .sensor-status {
        display: none;
        justify-content: center;
        gap: 16px;
        padding: 10px 14px;
        border-radius: 10px;
        background: rgba(30, 41, 59, 0.7);
        border: 1px solid rgba(71, 85, 105, 0.4);
        margin-bottom: 16px;
      }

      .sensor-status.active {
        display: flex;
      }

      .sensor-item {
        display: flex;
        align-items: center;
        gap: 6px;
        font-size: 13px;
        font-weight: 600;
      }

      .sensor-item.on {
        color: #4ade80;
      }

      .sensor-item.off {
        color: #64748b;
      }

      .sensor-dot {
        width: 6px;
        height: 6px;
        border-radius: 50%;
        background: #4ade80;
        animation: pulse 1.5s infinite;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="lang-toggle">
        <button id="lang-en" class="lang-btn active" type="button">EN</button>
        <button id="lang-he" class="lang-btn" type="button">×¢×‘</button>
      </div>

      <div id="pairing-screen">
        <div class="header">
          <div class="logo">ğŸ›¡ï¸</div>
          <h1 id="title">Connect Camera</h1>
          <div class="subtitle" id="subtitle">Enter the 6-digit code from your dashboard</div>
        </div>

        <div class="code-section">
          <label class="code-label" id="code-label">Pairing Code</label>
          <div class="code-inputs" id="code-inputs">
            <input class="code-input" inputmode="numeric" maxlength="1" />
            <input class="code-input" inputmode="numeric" maxlength="1" />
            <input class="code-input" inputmode="numeric" maxlength="1" />
            <input class="code-input" inputmode="numeric" maxlength="1" />
            <input class="code-input" inputmode="numeric" maxlength="1" />
            <input class="code-input" inputmode="numeric" maxlength="1" />
          </div>

          <button class="paste-btn" id="paste-btn" type="button">ğŸ“‹ <span id="paste-text">Paste Code</span></button>
          <div class="hint-text" id="paste-hint">Tip: You can paste the full code and we will fill it automatically.</div>
        </div>

        <button class="submit-btn" id="connect-btn" type="button">Connect</button>
        <div class="error-message" id="error"></div>
      </div>

      <div id="success-screen" class="success-screen">
        <div class="success-icon">âœ…</div>
        <div class="success-title" id="success-title">Connected Successfully</div>
        <div class="success-subtitle" id="success-subtitle">Your camera is now linked to your account</div>

        <!-- Sensor Status Indicator (camera/mic) -->
        <div id="sensor-status" class="sensor-status">
          <div class="sensor-item off" id="sensor-camera">
            ğŸ“· <span id="sensor-camera-label">Camera</span>
          </div>
          <div class="sensor-item off" id="sensor-mic">
            ğŸ¤ <span id="sensor-mic-label">Mic</span>
          </div>
        </div>

        <!-- Away Mode Status -->
        <div id="away-mode-indicator" class="info-box" style="display: none; background: rgba(34, 197, 94, 0.15); border-color: rgba(34, 197, 94, 0.4);">
          <div class="info-box-title" style="color: #86efac;"><span>ğŸ </span> <span id="away-mode-title">Away Mode Active</span></div>
          <div class="info-box-text" id="away-mode-text">Camera is monitoring. Display will turn off.</div>
        </div>

        <div id="live-indicator" class="live-indicator">
          <span class="live-dot"></span>
          <span class="live-text" id="live-text">LIVE - Streaming</span>
        </div>

        <div class="info-box">
          <div class="info-box-title"><span>â„¹ï¸</span> <span id="bg-title">Background Operation</span></div>
          <div class="info-box-text" id="bg-text">
            The camera will continue to work in the background even when this window is closed or minimized.
            To reopen the app, click the AIGuard icon near the clock.
          </div>
        </div>

        <div class="action-buttons">
          <button class="minimize-btn" id="minimize-btn" type="button">ğŸ”½ <span id="minimize-text">Minimize to Background</span></button>
          <div>
            <button class="close-btn" id="exit-btn" type="button">â›” <span id="exit-text">Exit Application</span></button>
            <div class="warning-text" id="exit-warning">Warning: Exiting will stop the camera service</div>
          </div>
        </div>
      </div>

      <!-- User Returned Modal removed - Away Mode is controlled manually from Dashboard -->
    </div>

    <!-- BUILD ID (debug)
         If you don't see this in the Electron console, you're not running
         this updated index.html file (or DevTools console is filtered). -->
    <script>
      console.log("[UI] index.html build: electron-index-2026-02-08-v2.7.0");
      
      // ============================================================
      // Sensor Status Indicator - update UI for camera/mic
      // ============================================================
      function updateSensorIndicator({ motion, sound }) {
        const container = document.getElementById('sensor-status');
        const cameraEl = document.getElementById('sensor-camera');
        const micEl = document.getElementById('sensor-mic');
        if (!container || !cameraEl || !micEl) return;

        const isActive = motion || sound;
        container.classList.toggle('active', isActive);

        cameraEl.className = 'sensor-item ' + (motion ? 'on' : 'off');
        cameraEl.innerHTML = (motion ? 'ğŸ“· ' : 'ğŸ“· ') + '<span>' + (motion ? (document.documentElement.dir === 'rtl' ? '××¦×œ××” âœ“' : 'Camera âœ“') : (document.documentElement.dir === 'rtl' ? '××¦×œ××”' : 'Camera')) + '</span>' + (motion ? ' <span class="sensor-dot"></span>' : '');

        micEl.className = 'sensor-item ' + (sound ? 'on' : 'off');
        micEl.innerHTML = (sound ? 'ğŸ¤ ' : 'ğŸ¤ ') + '<span>' + (sound ? (document.documentElement.dir === 'rtl' ? '××™×§×¨×•×¤×•×Ÿ âœ“' : 'Mic âœ“') : (document.documentElement.dir === 'rtl' ? '××™×§×¨×•×¤×•×Ÿ' : 'Mic')) + '</span>' + (sound ? ' <span class="sensor-dot"></span>' : '');
      }
    </script>

    <!-- WebRTC logic (start/stop via IPC) -->
    <script src="renderer-webrtc.js"></script>

    <script>
      // ============================================================
      // BUILD ID (debug)
      // If you don't see this line in the Electron console, you're not
      // running the updated index.html file.
      // ============================================================
      const __ELECTRON_INDEX_BUILD_ID__ = "electron-index-2026-02-09-v2.9.0";
      console.log(`[UI] index.html build: ${__ELECTRON_INDEX_BUILD_ID__}`);
      
      // ============================================================
      // MONITORING SYSTEM - Inline MediaPipe Integration
      // VERSION: 2.5.0 - Startup grace period + isMonitoring guard
      // ============================================================
      (async function initMonitoringSystem() {
        console.log('[Monitoring] Initializing monitoring system v2.5.2...');
        
        // Supabase config (for event reporting)
        const SUPABASE_URL = 'https://zoripeohnedivxkvrpbi.supabase.co';
        const EVENTS_REPORT_ENDPOINT = `${SUPABASE_URL}/functions/v1/events-report`;
        
        // State
        let monitoringStream = null;
        let videoElement = null;
        let objectDetector = null;
        let isMonitoring = false;
        let isDetectorReady = false;
        let detectionLoopActive = false;
        let currentConfig = null;
        let deviceAuthToken = null;
        let deviceId = null;
        
        // Debouncing
        const lastDetectionTime = {};
        const DEBOUNCE_MS = 60000; // 60 seconds - prevent rapid firing
        let isProcessingEvent = false; // Block concurrent sends
        
        // CRITICAL: Startup grace period - no events for first 10 seconds
        const STARTUP_GRACE_PERIOD_MS = 10000;
        let monitoringStartedAt = null;
        
        // ============================================================
        // SOUND DETECTION STATE (YAMNet)
        // ============================================================
        let soundModel = null;
        let soundAudioContext = null;
        let soundMediaStream = null;
        let soundProcessor = null;
        let soundSource = null;
        let isSoundRunning = false;
        let isSoundModelReady = false;
        let soundAudioBuffer = [];
        const SOUND_SAMPLE_RATE = 16000;
        const SOUND_FRAME_LENGTH = 0.975; // ~1 second per inference
        const SOUND_SAMPLES_NEEDED = Math.floor(SOUND_SAMPLE_RATE * SOUND_FRAME_LENGTH);
        const SOUND_RMS_THRESHOLD = 0.01;
        let soundLastDetectionTime = {};
        let soundPersistenceCount = {};
        let soundScoreHistory = {};
        let isProcessingSoundEvent = false;
        
        // YAMNet target class indices
        const YAMNET_TARGET_CLASSES = {
          441: { label: 'glass_breaking', name: 'Shatter' },
          442: { label: 'glass_breaking', name: 'Splinter' },
          443: { label: 'glass_breaking', name: 'Crash' },
          22: { label: 'baby_crying', name: 'Crying, sobbing' },
          23: { label: 'baby_crying', name: 'Baby cry, infant cry' },
          24: { label: 'baby_crying', name: 'Whimper' },
          67: { label: 'dog_barking', name: 'Bark' },
          68: { label: 'dog_barking', name: 'Yip' },
          69: { label: 'dog_barking', name: 'Howl' },
          70: { label: 'dog_barking', name: 'Growling' },
          389: { label: 'alarm', name: 'Smoke detector, smoke alarm' },
          390: { label: 'alarm', name: 'Fire alarm' },
          392: { label: 'alarm', name: 'Buzzer' },
          394: { label: 'alarm', name: 'Alarm clock' },
          427: { label: 'gunshot', name: 'Gunshot, gunfire' },
          428: { label: 'gunshot', name: 'Machine gun' },
          429: { label: 'gunshot', name: 'Fusillade' },
          426: { label: 'explosion', name: 'Explosion' },
          20: { label: 'scream', name: 'Screaming' },
          21: { label: 'scream', name: 'Wail, moan' },
          19: { label: 'scream', name: 'Shout' },
          321: { label: 'door_knock', name: 'Knock' },
          322: { label: 'door_knock', name: 'Tap' },
          323: { label: 'door_sound', name: 'Door' },
          324: { label: 'door_sound', name: 'Doorbell' },
          396: { label: 'siren', name: 'Siren' },
          397: { label: 'siren', name: 'Civil defense siren' },
          398: { label: 'siren', name: 'Ambulance (siren)' },
          399: { label: 'siren', name: 'Fire engine, fire truck (siren)' },
          400: { label: 'siren', name: 'Police car (siren)' },
        };
        
        const SOUND_LABEL_POLICIES = {
          baby_crying:    { threshold: 0.60, persistence: 3, debounce_ms: 180000, event_type: 'sound_baby_cry',   category: 'informational' },
          door_knock:     { threshold: 0.50, persistence: 2, debounce_ms: 60000,  event_type: 'sound_disturbance', category: 'disturbance' },
          dog_barking:    { threshold: 0.50, persistence: 2, debounce_ms: 120000, event_type: 'sound_disturbance', category: 'disturbance' },
          scream:         { threshold: 0.45, persistence: 2, debounce_ms: 60000,  event_type: 'sound_disturbance', category: 'disturbance' },
          glass_breaking: { threshold: 0.45, persistence: 1, debounce_ms: 30000,  event_type: 'sound',            category: 'security' },
          alarm:          { threshold: 0.50, persistence: 1, debounce_ms: 30000,  event_type: 'sound',            category: 'security' },
          gunshot:        { threshold: 0.40, persistence: 1, debounce_ms: 30000,  event_type: 'sound',            category: 'security' },
          explosion:      { threshold: 0.40, persistence: 1, debounce_ms: 30000,  event_type: 'sound',            category: 'security' },
          siren:          { threshold: 0.50, persistence: 1, debounce_ms: 60000,  event_type: 'sound',            category: 'security' },
          door_sound:     { threshold: 0.50, persistence: 2, debounce_ms: 60000,  event_type: 'sound_disturbance', category: 'disturbance' },
        };
        
        let soundTargetLabels = new Set();
        
        // Label mapping from COCO to our categories
        const LABEL_MAPPING = {
          person: 'person',
          cat: 'animal', dog: 'animal', bird: 'animal', horse: 'animal',
          sheep: 'animal', cow: 'animal', elephant: 'animal', bear: 'animal',
          car: 'vehicle', truck: 'vehicle', bus: 'vehicle', motorcycle: 'vehicle',
          bicycle: 'vehicle', airplane: 'vehicle', boat: 'vehicle',
        };
        
        // ============================================================
        // Load MediaPipe Tasks Vision from CDN
        // ============================================================
        async function loadMediaPipe() {
          try {
            console.log('[Monitoring] Loading MediaPipe Tasks Vision from CDN...');
            
            // Import the library dynamically
            const vision = await import('https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.14/vision_bundle.mjs');
            const { ObjectDetector, FilesetResolver } = vision;
            
            console.log('[Monitoring] âœ“ MediaPipe library loaded');
            
            // Load WASM files
            const wasmFileset = await FilesetResolver.forVisionTasks(
              'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.14/wasm'
            );
            
            // Create object detector
            objectDetector = await ObjectDetector.createFromOptions(wasmFileset, {
              baseOptions: {
                modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite',
                delegate: 'GPU',
              },
              runningMode: 'VIDEO',
              maxResults: 5,
              scoreThreshold: 0.5,
            });
            
            isDetectorReady = true;
            console.log('[Monitoring] âœ“ Object detector initialized');
            return true;
          } catch (error) {
            console.error('[Monitoring] âœ— MediaPipe initialization failed:', error);
            return false;
          }
        }
        
        // ============================================================
        // Capture snapshot as base64
        // ============================================================
        function captureSnapshot() {
          if (!videoElement || videoElement.readyState < 2) return null;
          try {
            const canvas = document.createElement('canvas');
            canvas.width = videoElement.videoWidth || 640;
            canvas.height = videoElement.videoHeight || 480;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
            return canvas.toDataURL('image/jpeg', 0.8);
          } catch (e) {
            console.error('[Monitoring] Snapshot failed:', e);
            return null;
          }
        }
        
        // ============================================================
        // Send event to server
        // ============================================================
        async function sendEventToServer(eventData) {
          if (!deviceAuthToken || !deviceId) {
            console.warn('[Monitoring] Missing deviceAuthToken or deviceId, skipping event');
            return;
          }
          
          // CRITICAL: Check if monitoring is actually active
          if (!isMonitoring) {
            console.log('[Monitoring] Monitoring not active, skipping event');
            return;
          }
          
          // CRITICAL: Startup grace period - skip events in first 10 seconds
          if (monitoringStartedAt && (Date.now() - monitoringStartedAt) < STARTUP_GRACE_PERIOD_MS) {
            const elapsed = Date.now() - monitoringStartedAt;
            console.log(`[Monitoring] Startup grace period (${elapsed}ms/${STARTUP_GRACE_PERIOD_MS}ms) - skipping event`);
            return;
          }
          
          // Prevent concurrent sends - only one event at a time
          if (isProcessingEvent) {
            console.log('[Monitoring] Already processing an event, skipping');
            return;
          }
          
          try {
            isProcessingEvent = true;
            console.log(`[Monitoring] Sending event: ${eventData.label} (${(eventData.confidence * 100).toFixed(0)}%)`);
            
            const snapshot = captureSnapshot();
            
            // CRITICAL: Only send if we have a snapshot
            if (!snapshot) {
              console.log('[Monitoring] No snapshot available, skipping event');
              isProcessingEvent = false;
              return;
            }
            
            const response = await fetch(EVENTS_REPORT_ENDPOINT, {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
                'x-device-token': deviceAuthToken,
              },
              body: JSON.stringify({
                device_id: deviceId,
                event_type: 'motion',
                labels: [{ label: eventData.label, confidence: eventData.confidence }],
                snapshot: snapshot,
                timestamp: Date.now(),
                metadata: eventData.metadata || {},
              }),
            });
            
            if (!response.ok) {
              const errorText = await response.text();
              console.error('[Monitoring] Event report failed:', response.status, errorText);
            } else {
              const result = await response.json();
              console.log('[Monitoring] âœ“ Event reported:', result.ai_is_real ? 'REAL' : 'False Positive');
            }
          } catch (error) {
            console.error('[Monitoring] Event send error:', error);
          } finally {
            isProcessingEvent = false;
          }
        }
        
        // ============================================================
        // SOUND: Send sound event to server (no snapshot required)
        // ============================================================
        async function sendSoundEventToServer(eventData) {
          if (!deviceAuthToken || !deviceId) {
            console.warn('[Monitoring] Missing deviceAuthToken or deviceId, skipping sound event');
            return;
          }
          if (!isMonitoring) {
            console.log('[Monitoring] Monitoring not active, skipping sound event');
            return;
          }
          if (monitoringStartedAt && (Date.now() - monitoringStartedAt) < STARTUP_GRACE_PERIOD_MS) {
            console.log(`[Monitoring] Startup grace period - skipping sound event`);
            return;
          }
          if (isProcessingSoundEvent) {
            console.log('[Monitoring] Already processing a sound event, skipping');
            return;
          }
          
          try {
            isProcessingSoundEvent = true;
            console.log(`[Monitoring] ğŸ”Š Sending sound event: ${eventData.label} (${(eventData.confidence * 100).toFixed(0)}%)`);
            
            const response = await fetch(EVENTS_REPORT_ENDPOINT, {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
                'x-device-token': deviceAuthToken,
              },
              body: JSON.stringify({
                device_id: deviceId,
                event_type: eventData.event_type || 'sound',
                labels: [{ label: eventData.label, confidence: eventData.confidence }],
                snapshot: null,
                timestamp: Date.now(),
                metadata: eventData.metadata || {},
              }),
            });
            
            if (!response.ok) {
              const errorText = await response.text();
              console.error('[Monitoring] Sound event report failed:', response.status, errorText);
            } else {
              const result = await response.json();
              console.log('[Monitoring] âœ“ Sound event reported:', JSON.stringify({
                event_id: result.event_id,
                ai_is_real: result.ai_is_real,
                notification_sent: result.notification_sent,
              }));
            }
          } catch (error) {
            console.error('[Monitoring] Sound event send error:', error);
          } finally {
            isProcessingSoundEvent = false;
          }
        }
        
        // ============================================================
        // SOUND: Load TensorFlow.js + YAMNet
        // ============================================================
        async function loadYAMNet() {
          try {
            console.log('[Sound] Loading TensorFlow.js...');
            
            if (typeof tf === 'undefined') {
              await new Promise((resolve, reject) => {
                const script = document.createElement('script');
                script.src = 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.17.0/dist/tf.min.js';
                script.onload = resolve;
                script.onerror = reject;
                document.head.appendChild(script);
              });
              console.log('[Sound] âœ“ TensorFlow.js loaded');
            }
            
            await tf.ready();
            console.log('[Sound] TF.js backend:', tf.getBackend());
            
            console.log('[Sound] Loading YAMNet model...');
            // Load from local HTTP server (main.js serves monitoring/models/)
            const port = await window.electronAPI?.getModelServerPort?.();
            if (!port) {
              throw new Error('Local model server not running. Ensure YAMNet files exist in monitoring/models/yamnet/');
            }
            const localModelUrl = `http://127.0.0.1:${port}/yamnet/model.json`;
            console.log(`[Sound] Loading from: ${localModelUrl}`);
            soundModel = await tf.loadGraphModel(localModelUrl);
            
            const dummy = tf.zeros([15600]);
            const warmup = soundModel.predict(dummy);
            // warmup may be a single tensor or an array of tensors
            if (Array.isArray(warmup)) {
              warmup.forEach(t => t.dispose());
            } else {
              warmup.dispose();
            }
            dummy.dispose();
            
            isSoundModelReady = true;
            console.log('[Sound] âœ“ YAMNet model loaded and warmed up');
            return true;
          } catch (error) {
            console.error('[Sound] âœ— YAMNet initialization failed:', error);
            isSoundModelReady = false;
            return false;
          }
        }
        
        // ============================================================
        // SOUND: Start microphone capture + inference
        // ============================================================
        async function startSoundDetection(config) {
          if (isSoundRunning) {
            console.log('[Sound] Already running');
            return true;
          }
          
          if (!isSoundModelReady) {
            const loaded = await loadYAMNet();
            if (!loaded) {
              console.error('[Sound] Cannot start - model not loaded');
              return false;
            }
          }
          
          const targets = config?.sensors?.sound?.targets || ['glass_breaking', 'baby_crying', 'alarm', 'gunshot', 'scream'];
          soundTargetLabels = new Set(targets);
          console.log('[Sound] Target labels:', Array.from(soundTargetLabels));
          
          try {
            console.log('[Sound] Starting microphone capture...');
            soundMediaStream = await navigator.mediaDevices.getUserMedia({
              audio: {
                sampleRate: SOUND_SAMPLE_RATE,
                channelCount: 1,
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true,
              }
            });
            
            soundAudioContext = new AudioContext({ sampleRate: SOUND_SAMPLE_RATE });
            soundSource = soundAudioContext.createMediaStreamSource(soundMediaStream);
            soundProcessor = soundAudioContext.createScriptProcessor(4096, 1, 1);
            
            soundProcessor.onaudioprocess = (event) => {
              if (!isSoundRunning) return;
              const inputData = event.inputBuffer.getChannelData(0);
              processSoundChunk(new Float32Array(inputData));
            };
            
            soundSource.connect(soundProcessor);
            soundProcessor.connect(soundAudioContext.destination);
            
            isSoundRunning = true;
            soundAudioBuffer = [];
            soundPersistenceCount = {};
            soundScoreHistory = {};
            soundLastDetectionTime = {};
            
            console.log('[Sound] âœ“ Microphone capture started, inference running');
            return true;
          } catch (error) {
            console.error('[Sound] Failed to start microphone:', error);
            return false;
          }
        }
        
        // ============================================================
        // SOUND: Process audio chunk â†’ accumulate â†’ infer
        // ============================================================
        function processSoundChunk(chunk) {
          soundAudioBuffer.push(...chunk);
          
          if (soundAudioBuffer.length >= SOUND_SAMPLES_NEEDED) {
            const samples = new Float32Array(soundAudioBuffer.slice(0, SOUND_SAMPLES_NEEDED));
            soundAudioBuffer = soundAudioBuffer.slice(SOUND_SAMPLES_NEEDED);
            
            const rms = Math.sqrt(samples.reduce((sum, s) => sum + s * s, 0) / samples.length);
            if (rms < SOUND_RMS_THRESHOLD) {
              for (const label of Object.keys(soundPersistenceCount)) {
                soundPersistenceCount[label] = 0;
              }
              return;
            }
            
            runSoundInference(samples);
          }
        }
        
        // ============================================================
        // SOUND: Run YAMNet inference
        // ============================================================
        async function runSoundInference(samples) {
          try {
            const inputTensor = tf.tensor1d(samples);
            const output = soundModel.predict(inputTensor);
            
            const scores = Array.isArray(output) ? output[0] : output;
            const scoresData = await scores.data();
            
            const numClasses = 521;
            const numFrames = scoresData.length / numClasses;
            
            const avgScores = new Float32Array(numClasses);
            for (let c = 0; c < numClasses; c++) {
              let sum = 0;
              for (let f = 0; f < numFrames; f++) {
                sum += scoresData[f * numClasses + c];
              }
              avgScores[c] = sum / numFrames;
            }
            
            processSoundScores(avgScores);
            
            inputTensor.dispose();
            if (Array.isArray(output)) {
              output.forEach(t => t.dispose());
            } else {
              output.dispose();
            }
          } catch (error) {
            console.error('[Sound] Inference error:', error);
          }
        }
        
        // ============================================================
        // SOUND: Process scores with per-label policies
        // ============================================================
        function processSoundScores(scores) {
          const now = Date.now();
          const labelBestScores = {};
          
          for (const [indexStr, classInfo] of Object.entries(YAMNET_TARGET_CLASSES)) {
            const index = parseInt(indexStr);
            const score = scores[index];
            const label = classInfo.label;
            
            if (!soundTargetLabels.has(label)) continue;
            
            if (!labelBestScores[label] || score > labelBestScores[label].score) {
              labelBestScores[label] = { score, name: classInfo.name, classIndex: index };
            }
          }
          
          for (const [label, best] of Object.entries(labelBestScores)) {
            const policy = SOUND_LABEL_POLICIES[label] || { threshold: 0.50, persistence: 1, debounce_ms: 60000, event_type: 'sound', category: 'security' };
            
            if (best.score < policy.threshold) {
              soundPersistenceCount[label] = 0;
              continue;
            }
            
            soundPersistenceCount[label] = (soundPersistenceCount[label] || 0) + 1;
            
            if (!soundScoreHistory[label]) soundScoreHistory[label] = [];
            soundScoreHistory[label].push(best.score);
            if (soundScoreHistory[label].length > 10) soundScoreHistory[label].shift();
            
            if (soundPersistenceCount[label] < policy.persistence) continue;
            
            const lastTime = soundLastDetectionTime[label] || 0;
            if (now - lastTime < policy.debounce_ms) continue;
            
            // â•â•â• Sound Detection confirmed! â•â•â•
            const scoreHist = soundScoreHistory[label] || [];
            soundPersistenceCount[label] = 0;
            soundLastDetectionTime[label] = now;
            
            console.log(`[Sound] âœ“ DETECTED: ${best.name} â†’ ${label} [${policy.category}] (${(best.score * 100).toFixed(1)}%) persistence=${policy.persistence}`);
            
            const audioCtxMeta = policy.category === 'informational' ? {
              score_history: scoreHist.slice(-10),
              avg_score: scoreHist.length > 0 ? scoreHist.reduce((a, b) => a + b, 0) / scoreHist.length : best.score,
              peak_score: scoreHist.length > 0 ? Math.max(...scoreHist) : best.score,
              consecutive_windows: policy.persistence,
              requires_ai_verification: true,
            } : null;
            
            sendSoundEventToServer({
              label: label,
              confidence: best.score,
              event_type: policy.event_type,
              metadata: {
                yamnet_class: best.name,
                yamnet_index: best.classIndex,
                category: policy.category,
                persistence_windows: policy.persistence,
                ...(audioCtxMeta ? { audio_context: audioCtxMeta } : {}),
              },
            });
            
            window.electronAPI?.sendMonitoringEvent?.({
              sensor_type: policy.event_type,
              label: label,
              confidence: best.score,
              timestamp: now,
              metadata: { yamnet_class: best.name, category: policy.category },
            });
          }
        }
        
        // ============================================================
        // SOUND: Stop sound detection
        // ============================================================
        function stopSoundDetection() {
          console.log('[Sound] Stopping...');
          isSoundRunning = false;
          
          if (soundProcessor) { soundProcessor.disconnect(); soundProcessor = null; }
          if (soundSource) { soundSource.disconnect(); soundSource = null; }
          if (soundMediaStream) {
            soundMediaStream.getTracks().forEach(track => {
              track.stop();
              console.log('[Sound] Stopped mic track:', track.label);
            });
            soundMediaStream = null;
          }
          if (soundAudioContext && soundAudioContext.state !== 'closed') {
            soundAudioContext.close();
            soundAudioContext = null;
          }
          
          soundAudioBuffer = [];
          soundPersistenceCount = {};
          soundScoreHistory = {};
          soundLastDetectionTime = {};
          console.log('[Sound] âœ“ Stopped');
        }
        
        // ============================================================
        // Detection loop
        // ============================================================
        let lastFrameTime = 0;
        const DETECTION_INTERVAL_MS = 200; // 5 FPS
        let detectionLoopTimer = null;
        
        function runDetectionLoop() {
          // IMPORTANT: Do NOT rely on requestAnimationFrame.
          // When the Electron window is hidden/minimized to Tray, Chromium may stop/throttle rAF,
          // which makes motion detection only run when the window is visible.
          if (!detectionLoopActive || !objectDetector || !videoElement) return;

          if (detectionLoopTimer) {
            clearTimeout(detectionLoopTimer);
            detectionLoopTimer = null;
          }

          const tick = () => {
            if (!detectionLoopActive || !objectDetector || !videoElement) return;

            const now = performance.now();

            if (now - lastFrameTime >= DETECTION_INTERVAL_MS) {
              lastFrameTime = now;

              if (videoElement.readyState >= 2 && !videoElement.paused) {
                try {
                  const detections = objectDetector.detectForVideo(videoElement, now);
                  processDetections(detections.detections);
                } catch (e) {
                  // Ignore frame errors
                }
              }
            }

            detectionLoopTimer = setTimeout(tick, DETECTION_INTERVAL_MS);
          };

          tick();
        }
        
        function processDetections(detections) {
          const nowMs = Date.now();
          const targets = currentConfig?.sensors?.motion?.targets || ['person', 'animal', 'vehicle'];
          const threshold = currentConfig?.sensors?.motion?.confidence_threshold || 0.6;
          const debounceMs = currentConfig?.sensors?.motion?.debounce_ms || DEBOUNCE_MS;
          
          for (const detection of detections) {
            if (!detection.categories || detection.categories.length === 0) continue;
            
            const category = detection.categories[0];
            const rawLabel = category.categoryName.toLowerCase();
            const confidence = category.score;
            
            const mappedLabel = LABEL_MAPPING[rawLabel];
            if (!mappedLabel) continue;
            if (!targets.includes(mappedLabel)) continue;
            if (confidence < threshold) continue;
            
            // Debounce check
            const lastTime = lastDetectionTime[mappedLabel] || 0;
            if (nowMs - lastTime < debounceMs) continue;
            
            lastDetectionTime[mappedLabel] = nowMs;
            
            console.log(`[Monitoring] ğŸ¯ Detected: ${rawLabel} â†’ ${mappedLabel} (${(confidence * 100).toFixed(1)}%)`);
            
            // Send to server
            sendEventToServer({
              label: mappedLabel,
              confidence: confidence,
              metadata: {
                raw_label: rawLabel,
                bounding_box: detection.boundingBox ? {
                  x: detection.boundingBox.originX,
                  y: detection.boundingBox.originY,
                  width: detection.boundingBox.width,
                  height: detection.boundingBox.height,
                } : null,
              },
            });
            
            // Also send to main process via IPC
            window.electronAPI?.sendMonitoringEvent?.({
              sensor_type: 'motion',
              label: mappedLabel,
              confidence: confidence,
              timestamp: nowMs,
            });
          }
        }
        
        // ============================================================
        // Stop monitoring resources (for clean-start)
        // ============================================================
        function stopMonitoringResources(options = {}) {
          const silent = options.silent || false;
          if (!silent) console.log('[Monitoring] Releasing existing resources...');
          
          detectionLoopActive = false;

          if (detectionLoopTimer) {
            clearTimeout(detectionLoopTimer);
            detectionLoopTimer = null;
          }
          
          if (monitoringStream) {
            monitoringStream.getTracks().forEach(track => {
              track.stop();
              if (!silent) console.log('[Monitoring] Stopped track:', track.kind, track.label);
            });
            monitoringStream = null;
          }
          
          if (videoElement && videoElement.srcObject) {
            videoElement.srcObject = null;
          }
          
          // Also stop sound detection on clean-start
          if (isSoundRunning) {
            stopSoundDetection();
          }
        }
        
        // ============================================================
        // Helper: Try getUserMedia with constraints
        // ============================================================
        async function tryGetUserMedia(constraints, label) {
          console.log(`[Monitoring] Trying getUserMedia: ${label}...`);
          try {
            const stream = await navigator.mediaDevices.getUserMedia(constraints);
            console.log(`[Monitoring] âœ“ getUserMedia succeeded (${label})`);
            return stream;
          } catch (err) {
            console.warn(`[Monitoring] âœ— getUserMedia failed (${label}):`, err.name, err.message);
            return null;
          }
        }
        
        // ============================================================
        // Build bilingual error message
        // ============================================================
        function buildMonitoringErrorMessage(err) {
          const name = err.name || 'Error';
          const msg = err.message || 'Unknown';
          
          if (name === 'NotReadableError') {
            return `Camera busy/unavailable (NotReadableError): ${msg} | ××¦×œ××” ×ª×¤×•×¡×”/×œ× ×–××™× ×” â€“ ×¡×’×•×¨ ×ª×•×›× ×•×ª ××—×¨×•×ª ×©××©×ª××©×•×ª ×‘××¦×œ××” ×•× ×¡×” ×©×•×‘`;
          }
          if (name === 'NotAllowedError') {
            return `Camera permission denied (NotAllowedError): ${msg} | ×”×¨×©××ª ××¦×œ××” × ×“×—×ª×” â€“ ××©×¨ ×”×¨×©××” ×‘×”×’×“×¨×•×ª ×”××¢×¨×›×ª`;
          }
          if (name === 'OverconstrainedError') {
            return `Camera constraints not supported (OverconstrainedError): ${msg} | ×”×’×“×¨×•×ª ×”××¦×œ××” ×œ× × ×ª××›×•×ª â€“ × ×¡×” ××¦×œ××” ××—×¨×ª`;
          }
          if (name === 'NotFoundError') {
            return `No camera found (NotFoundError): ${msg} | ×œ× × ××¦××” ××¦×œ××” â€“ ×—×‘×¨ ××¦×œ××” ×œ××—×©×‘`;
          }
          return `Camera error (${name}): ${msg} | ×©×’×™××ª ××¦×œ××”: ${msg}`;
        }
        
        // ============================================================
        // Start monitoring (v2.3.2 - with fallbacks + clean-start)
        // ============================================================
        async function startMonitoring(config) {
          console.log('[Monitoring] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
          console.log('[Monitoring] Starting monitoring v2.6.0 with config:', JSON.stringify(config, null, 2));
          console.log('[Monitoring] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
          currentConfig = config;
          
          // CLEAN-START: Release any existing resources first
          stopMonitoringResources({ silent: true });
          
          // CRITICAL: Reset startup timestamp for grace period
          monitoringStartedAt = null;
          
          const motionEnabled = config?.sensors?.motion?.enabled ?? false;
          const soundEnabled = config?.sensors?.sound?.enabled ?? false;
          
          console.log('[Monitoring] Sensor config:', { motionEnabled, soundEnabled });
          
          try {
            let motionStarted = false;
            let soundStarted = false;
            
            // ============================================================
            // MOTION: Only activate camera if motion detection is enabled
            // ============================================================
            if (motionEnabled) {
              console.log('[Monitoring] Motion enabled - requesting camera access...');
              
              // Progressive fallback for camera constraints
              monitoringStream = await tryGetUserMedia(
                { video: { width: { ideal: 640 }, height: { ideal: 480 }, frameRate: { ideal: 15 } }, audio: false },
                'preferred 640x480@15'
              );
              
              if (!monitoringStream) {
                monitoringStream = await tryGetUserMedia(
                  { video: { width: { max: 1280 }, height: { max: 720 } }, audio: false },
                  'relaxed max 1280x720'
                );
              }
              
              if (!monitoringStream) {
                monitoringStream = await tryGetUserMedia(
                  { video: true, audio: false },
                  'minimal video:true'
                );
              }
              
              if (!monitoringStream) {
                console.error('[Monitoring] âœ— All camera attempts failed');
                // Don't throw - sound detection can still work without camera
                if (!soundEnabled) {
                  throw new Error('Camera unavailable and sound not enabled');
                }
              } else {
                console.log('[Monitoring] âœ“ Camera acquired - LED should be ON now');
                
                // Create hidden video element
                videoElement = document.getElementById('monitoring-video');
                if (!videoElement) {
                  videoElement = document.createElement('video');
                  videoElement.id = 'monitoring-video';
                  videoElement.autoplay = true;
                  videoElement.muted = true;
                  videoElement.playsInline = true;
                  videoElement.style.position = 'absolute';
                  videoElement.style.left = '-9999px';
                  videoElement.style.width = '640px';
                  videoElement.style.height = '480px';
                  document.body.appendChild(videoElement);
                }
                
                videoElement.srcObject = monitoringStream;
                await videoElement.play();
                
                // Initialize MediaPipe detector if not done
                if (!isDetectorReady) {
                  const mpResult = await loadMediaPipe();
                  console.log('[Monitoring] MediaPipe load result:', mpResult);
                }
                
                // Start detection loop
                if (isDetectorReady) {
                  detectionLoopActive = true;
                  motionStarted = true;
                  console.log('[Monitoring] âœ“ Motion detection loop started');
                  runDetectionLoop();
                }
              }
            } else {
              console.log('[Monitoring] Motion DISABLED - camera stays OFF ğŸ“·ğŸš«');
            }
            
            // ============================================================
            // SOUND: Independent, non-blocking subsystem
            // Sound failure must NEVER block ACK or affect motion
            // ============================================================
            let soundError = null;
            if (soundEnabled) {
              try {
                console.log('[Monitoring] Sound enabled - starting YAMNet microphone detection...');
                const soundOk = await startSoundDetection(config);
                if (soundOk) {
                  soundStarted = true;
                  console.log('[Monitoring] âœ“ Sound detection started (YAMNet + microphone)');
                } else {
                  soundError = 'Sound detection failed to start (model or microphone unavailable)';
                  console.error('[Monitoring] âœ— Sound detection failed to start');
                }
              } catch (soundErr) {
                soundError = soundErr.message || 'Unknown sound error';
                console.error('[Monitoring] âœ— Sound detection threw error (non-blocking):', soundErr);
              }
            }
            
            // Mark monitoring as active - ALWAYS, even if sound failed
            isMonitoring = true;
            monitoringStartedAt = Date.now();
            console.log('[Monitoring] âœ“ Grace period started (10s)');
            
            // CRITICAL: ACK is ALWAYS sent, regardless of sound status
            const ackPayload = {
              motion: motionStarted,
              sound: soundStarted,
              errors: soundError ? { sound: soundError } : undefined,
            };
            console.log('[Monitoring] Sending ACK to main process...');
            window.electronAPI?.notifyMonitoringStarted?.(ackPayload);
            console.log('[Monitoring] âœ“ Sent monitoring-started ACK:', JSON.stringify(ackPayload));
            
            // Update sensor status indicator in UI
            updateSensorIndicator({ motion: motionStarted, sound: soundStarted });
          } catch (error) {
            console.error('[Monitoring] âœ— Start failed:', error);
            console.error('[Monitoring] Error name:', error.name);
            console.error('[Monitoring] Error message:', error.message);
            
            const bilingual = buildMonitoringErrorMessage(error);
            console.error('[Monitoring] Full error:', bilingual);
            
            // CRITICAL: Even on total failure, send ACK not error
            // to prevent main process timeout
            window.electronAPI?.notifyMonitoringStarted?.({
              motion: false,
              sound: false,
              errors: { system: bilingual },
            });
          }
        }
        
        // ============================================================
        // Stop monitoring
        // ============================================================
        function stopMonitoring() {
          console.log('[Monitoring] Stopping monitoring...');
          
          detectionLoopActive = false;
          isMonitoring = false;
          monitoringStartedAt = null;

          if (detectionLoopTimer) {
            clearTimeout(detectionLoopTimer);
            detectionLoopTimer = null;
          }
          
          if (monitoringStream) {
            monitoringStream.getTracks().forEach(track => {
              track.stop();
              console.log('[Monitoring] Stopped track:', track.kind);
            });
            monitoringStream = null;
          }
          
          if (videoElement) {
            videoElement.srcObject = null;
          }
          
          // Stop sound detection
          stopSoundDetection();
          
          window.electronAPI?.notifyMonitoringStopped?.();
          updateSensorIndicator({ motion: false, sound: false });
          console.log('[Monitoring] âœ“ Monitoring stopped');
        }
        
        // ============================================================
        // IPC Listeners
        // ============================================================
        if (window.electronAPI?.onStartMonitoring) {
          window.electronAPI.onStartMonitoring(async (config) => {
            console.log('[Monitoring] Received START_MONITORING command');
            
            // Get device credentials from main process store
            // They should be passed in config or we need to get them separately
            deviceId = config?.device_id || localStorage.getItem('device_id');
            deviceAuthToken = config?.device_auth_token || localStorage.getItem('device_auth_token');
            
            if (!deviceId || !deviceAuthToken) {
              console.warn('[Monitoring] âš ï¸ Missing device credentials - events won\'t be reported to server');
            }
            
            await startMonitoring(config);
          });
          console.log('[Monitoring] âœ“ onStartMonitoring listener registered');
        }
        
        if (window.electronAPI?.onStopMonitoring) {
          window.electronAPI.onStopMonitoring(() => {
            console.log('[Monitoring] Received STOP_MONITORING command');
            stopMonitoring();
          });
          console.log('[Monitoring] âœ“ onStopMonitoring listener registered');
        }
        
        // ============================================================
        // Clip Recording - triggered by Main after AI validates event
        // ============================================================
        if (window.electronAPI?.onStartClipRecording) {
          window.electronAPI.onStartClipRecording(async ({ eventId, durationSeconds }) => {
            console.log(`[ClipRecorder] Recording requested: event=${eventId}, duration=${durationSeconds}s`);
            
            if (!monitoringStream || !videoElement) {
              console.warn('[ClipRecorder] No active monitoring stream, skipping clip');
              return;
            }
            
            try {
              const recorder = new MediaRecorder(monitoringStream, {
                mimeType: 'video/webm;codecs=vp9',
                videoBitsPerSecond: 2500000,
              });
              
              const chunks = [];
              
              recorder.ondataavailable = (e) => {
                if (e.data.size > 0) chunks.push(e.data);
              };
              
              recorder.onstop = async () => {
                console.log(`[ClipRecorder] Recording stopped, ${chunks.length} chunks`);
                const blob = new Blob(chunks, { type: 'video/webm' });
                
                // Convert to base64
                const reader = new FileReader();
                reader.onloadend = async () => {
                  const base64 = reader.result.split(',')[1]; // strip data:... prefix
                  const filename = `${eventId}_${Date.now()}.webm`;
                  
                  console.log(`[ClipRecorder] Saving clip: ${filename} (${(blob.size / 1024 / 1024).toFixed(2)} MB)`);
                  
                  const result = await window.electronAPI.saveClip({
                    filename,
                    base64Data: base64,
                    eventId,
                    durationSeconds,
                  });
                  
                  if (result.success) {
                    console.log(`[ClipRecorder] âœ“ Clip saved: ${result.filepath}`);
                    window.electronAPI.notifyClipRecorded({
                      eventId,
                      filename,
                      durationSeconds,
                      filepath: result.filepath,
                    });
                  } else {
                    console.error(`[ClipRecorder] âœ— Save failed:`, result.error);
                  }
                };
                reader.readAsDataURL(blob);
              };
              
              recorder.start();
              console.log(`[ClipRecorder] âœ“ Recording started (${durationSeconds}s)`);
              
              setTimeout(() => {
                if (recorder.state === 'recording') {
                  recorder.stop();
                  console.log('[ClipRecorder] Timer expired, stopping recorder');
                }
              }, durationSeconds * 1000);
              
            } catch (err) {
              console.error('[ClipRecorder] Recording error:', err);
            }
          });
          console.log('[Monitoring] âœ“ onStartClipRecording listener registered');
        }
        
        // Pre-load MediaPipe in background
        loadMediaPipe().then(success => {
          console.log('[Monitoring] MediaPipe pre-load:', success ? 'ready' : 'failed');
        });
        
        console.log('[Monitoring] âœ“ Monitoring system initialized');
      })();
      // ============================================================
      // CONFIG (SUPABASE_URL is already defined in renderer-webrtc.js)
      // ============================================================

      // ============================================================
      // I18N
      // ============================================================
      const STRINGS = {
        en: {
          dir: "ltr",
          title: "Connect Camera",
          subtitle: "Enter the 6-digit code from your dashboard",
          codeLabel: "Pairing Code",
          pasteText: "Paste Code",
          pasteHint: "Tip: You can paste the full code and we will fill it automatically.",
          connect: "Connect",
          successTitle: "Connected Successfully",
          successSubtitle: "Your camera is now linked to your account",
          live: "LIVE - Streaming",
          bgTitle: "Background Operation",
          bgText:
            "The camera will continue to work in the background even when this window is closed or minimized.\nTo reopen the app, click the AIGuard icon near the clock.",
          minimize: "Minimize to Background",
          exit: "Exit Application",
          exitWarning: "Warning: Exiting will stop the camera service",
          errClipboard: "Could not read clipboard. Please paste the code manually.",
          errInvalid: "Please enter a 6-digit code.",
          errVerify: "Invalid or expired code.",
          errGeneric: "Something went wrong. Please try again.",
          connecting: "Connectingâ€¦",
          // Away Mode
          awayModeTitle: "Away Mode Active",
          awayModeText: "Camera is monitoring. Display will turn off.",
          userReturnedTitle: "Welcome Back",
          userReturnedMessage: "You have returned. Would you like to disable Away Mode?",
          disableAwayMode: "Disable Away Mode",
          keepAwayMode: "Keep Away Mode"
        },
        he: {
          dir: "rtl",
          title: "×—×™×‘×•×¨ ××¦×œ××”",
          subtitle: "×”×–×Ÿ/×™ ×§×•×“ ×‘×Ÿ 6 ×¡×¤×¨×•×ª ××”×“×©×‘×•×¨×“",
          codeLabel: "×§×•×“ ×¦×™××•×“",
          pasteText: "×”×“×‘×§ ×§×•×“",
          pasteHint: "×˜×™×¤: ××¤×©×¨ ×œ×”×“×‘×™×§ ××ª ×›×œ ×”×§×•×“ ×•×× ×—× ×• × ××œ× ××•×ª×• ××•×˜×•××˜×™×ª.",
          connect: "×”×ª×—×‘×¨",
          successTitle: "×—×™×‘×•×¨ ×”×¦×œ×™×—",
          successSubtitle: "×”××¦×œ××” ×§×•×©×¨×” ×œ×—×©×‘×•×Ÿ ×©×œ×š",
          live: "LIVE - ×©×™×“×•×¨ ×¤×¢×™×œ",
          bgTitle: "×¤×¢×™×œ×•×ª ×‘×¨×§×¢",
          bgText:
            "×”××¦×œ××” ×ª××©×™×š ×œ×¢×‘×•×“ ×‘×¨×§×¢ ×’× ×× ×”×—×œ×•×Ÿ × ×¡×’×¨ ××• ×××•×–×¢×¨.\n×›×“×™ ×œ×¤×ª×•×— ×©×•×‘, ×œ×—×¥/×™ ×¢×œ ×”××™×™×§×•×Ÿ ×œ×™×“ ×”×©×¢×•×Ÿ.",
          minimize: "××–×¢×¨ ×œ×¨×§×¢",
          exit: "×™×¦×™××” ××”××¤×œ×™×§×¦×™×”",
          exitWarning: "××–×”×¨×”: ×™×¦×™××” ×ª×¢×¦×•×¨ ××ª ×©×™×¨×•×ª ×”××¦×œ××”",
          errClipboard: "×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××”×œ×•×—. × × ×œ×”×“×‘×™×§ ×™×“× ×™×ª.",
          errInvalid: "× × ×œ×”×–×™×Ÿ ×§×•×“ ×‘×Ÿ 6 ×¡×¤×¨×•×ª.",
          errVerify: "×§×•×“ ×œ× ×ª×§×™×Ÿ ××• ×¤×’ ×ª×•×§×£.",
          errGeneric: "××©×”×• ×”×©×ª×‘×©. × ×¡×”/×™ ×©×•×‘.",
          connecting: "××ª×—×‘×¨â€¦",
          // Away Mode
          awayModeTitle: "××¦×‘ ××¨×•×—×§ ×¤×¢×™×œ",
          awayModeText: "×”××¦×œ××” ×‘××¦×‘ × ×™×˜×•×¨. ×”××¡×š ×™×›×‘×”.",
          userReturnedTitle: "×‘×¨×•×š ×©×•×‘×š",
          userReturnedMessage: "×—×–×¨×ª ×”×‘×™×ª×”. ×”×× ×œ×›×‘×•×ª ××ª ××¦×‘ ××¨×•×—×§?",
          disableAwayMode: "×›×‘×” ××¦×‘ ××¨×•×—×§",
          keepAwayMode: "×”×©××¨ ××¦×‘ ××¨×•×—×§"
        }
      };

      let currentLang = "en";

      function setLanguage(lang) {
        currentLang = lang;
        const t = STRINGS[lang];

        document.documentElement.lang = lang;
        document.documentElement.dir = t.dir;

        document.getElementById("lang-en").classList.toggle("active", lang === "en");
        document.getElementById("lang-he").classList.toggle("active", lang === "he");

        document.getElementById("title").textContent = t.title;
        document.getElementById("subtitle").textContent = t.subtitle;
        document.getElementById("code-label").textContent = t.codeLabel;
        document.getElementById("paste-text").textContent = t.pasteText;
        document.getElementById("paste-hint").textContent = t.pasteHint;
        document.getElementById("connect-btn").textContent = t.connect;

        document.getElementById("success-title").textContent = t.successTitle;
        document.getElementById("success-subtitle").textContent = t.successSubtitle;
        document.getElementById("live-text").textContent = t.live;
        document.getElementById("bg-title").textContent = t.bgTitle;
        document.getElementById("bg-text").textContent = t.bgText;
        document.getElementById("minimize-text").textContent = t.minimize;
        document.getElementById("exit-text").textContent = t.exit;
        document.getElementById("exit-warning").textContent = t.exitWarning;
      }

      // ============================================================
      // PAIRING UI HELPERS
      // ============================================================
      const codeInputs = Array.from(document.querySelectorAll(".code-input"));
      const errorEl = document.getElementById("error");
      const connectBtn = document.getElementById("connect-btn");
      const pasteBtn = document.getElementById("paste-btn");

      function showError(msg) {
        errorEl.textContent = msg;
        errorEl.style.display = "block";
      }

      function clearError() {
        errorEl.textContent = "";
        errorEl.style.display = "none";
      }

      function getCode() {
        return codeInputs.map((i) => (i.value || "").replace(/\D/g, "")).join("").slice(0, 6);
      }

      function setCode(code) {
        const digits = String(code || "")
          .replace(/\D/g, "")
          .slice(0, 6)
          .split("");

        for (let idx = 0; idx < codeInputs.length; idx++) {
          codeInputs[idx].value = digits[idx] || "";
        }

        const nextIndex = Math.min(digits.length, codeInputs.length - 1);
        codeInputs[nextIndex].focus();
      }

      async function readClipboardText() {
        // Electron usually supports navigator.clipboard in secure contexts,
        // but fallback to prompt for reliability.
        if (navigator.clipboard && navigator.clipboard.readText) {
          return navigator.clipboard.readText();
        }
        return null;
      }

      function showSuccessScreen() {
        document.getElementById("pairing-screen").style.display = "none";
        document.getElementById("success-screen").style.display = "block";
      }

      function setLiveIndicator(isLive) {
        document.getElementById("live-indicator").classList.toggle("active", !!isLive);
      }

      // ============================================================
      // INPUT BEHAVIOR (auto-advance, backspace)
      // ============================================================
      codeInputs.forEach((input, idx) => {
        input.addEventListener("input", (e) => {
          clearError();
          const v = String(e.target.value || "").replace(/\D/g, "");
          e.target.value = v.slice(-1);
          if (e.target.value && idx < codeInputs.length - 1) {
            codeInputs[idx + 1].focus();
          }
        });

        input.addEventListener("keydown", (e) => {
          if (e.key === "Backspace" && !input.value && idx > 0) {
            codeInputs[idx - 1].focus();
          }
          if (e.key === "Enter") {
            connectBtn.click();
          }
        });

        input.addEventListener("paste", (e) => {
          const text = (e.clipboardData || window.clipboardData)?.getData("text") || "";
          const digits = text.replace(/\D/g, "").slice(0, 6);
          if (digits.length) {
            e.preventDefault();
            setCode(digits);
          }
        });
      });

      pasteBtn.addEventListener("click", async () => {
        clearError();
        const t = STRINGS[currentLang];
        try {
          const text = (await readClipboardText()) || prompt(t.pasteText) || "";
          const digits = String(text).replace(/\D/g, "").slice(0, 6);
          if (!digits) {
            showError(t.errClipboard);
            return;
          }
          setCode(digits);
        } catch (e) {
          showError(t.errClipboard);
        }
      });

      // ============================================================
      // PAIRING (Edge Function)
      // ============================================================
      async function verifyPairingCode(code) {
        const res = await fetch(`${SUPABASE_URL}/functions/v1/verify-pairing-code`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ code }),
        });

        const data = await res.json().catch(() => ({}));
        if (!res.ok) {
          const err = data?.error || "verify_failed";
          throw new Error(err);
        }
        return data;
      }

      connectBtn.addEventListener("click", async () => {
        clearError();
        const t = STRINGS[currentLang];

        const code = getCode();
        if (code.length !== 6) {
          showError(t.errInvalid);
          return;
        }

        const originalText = connectBtn.textContent;
        connectBtn.disabled = true;
        connectBtn.textContent = t.connecting;

        try {
          const data = await verifyPairingCode(code);

          // IMPORTANT: keep snake_case for IPC sync
          console.log('[UI] Pairing verified. electronAPI.loginUser available:', !!window.electronAPI?.loginUser);

          if (window.electronAPI?.loginUser) {
            console.log('[UI] Sending login-user IPC to main...', {
              profile_id: data.profile_id,
              device_id: data.device_id,
              has_session_token: !!data.session_token,
            });
            window.electronAPI.loginUser({
              profile_id: data.profile_id,
              session_token: data.session_token,
              device_id: data.device_id,
            });
          } else {
            console.warn(
              '[UI] WARNING: electronAPI.loginUser is missing. Main process will NOT receive profile_id/device_id, so Auto-Away cannot run.'
            );
          }

          showSuccessScreen();
        } catch (e) {
          const msg = String(e?.message || "");
          if (msg.toLowerCase().includes("invalid") || msg.toLowerCase().includes("expired")) {
            showError(t.errVerify);
          } else {
            showError(t.errGeneric);
          }
        } finally {
          connectBtn.disabled = false;
          connectBtn.textContent = originalText;
        }
      });

      // ============================================================
      // SUCCESS SCREEN ACTIONS
      // ============================================================
      document.getElementById("minimize-btn").addEventListener("click", () => {
        window.electronAPI?.minimizeToTray?.();
      });

      document.getElementById("exit-btn").addEventListener("click", () => {
        window.electronAPI?.exitApp?.();
      });

      // ============================================================
      // IPC -> UI live indicator (NOTE: actual WebRTC logic is in renderer-webrtc.js)
      // ============================================================
      // DO NOT register onStartLiveView/onStopLiveView here - it would override 
      // the WebRTC handlers in renderer-webrtc.js. The UI indicator is now 
      // handled via a separate approach if needed.

      // Allow main process to switch to success screen (auto-login)
      if (window.electronAPI?.onShowSuccessScreen) {
        window.electronAPI.onShowSuccessScreen(() => {
          showSuccessScreen();
        });
      }

      // ============================================================
      // AWAY MODE UI HANDLERS
      // ============================================================
      const awayModeIndicator = document.getElementById("away-mode-indicator");

      function setAwayModeIndicator(active) {
        if (awayModeIndicator) {
          awayModeIndicator.style.display = active ? "block" : "none";
        }
      }

      // Away Mode IPC listeners
      if (window.electronAPI) {
        window.electronAPI.onAwayModeEnabled?.(() => {
          console.log("[UI] Away Mode enabled");
          setAwayModeIndicator(true);
        });

        window.electronAPI.onAwayModeDisabled?.(() => {
          console.log("[UI] Away Mode disabled");
          setAwayModeIndicator(false);
        });

        window.electronAPI.onAwayModePreflightFailed?.((errors) => {
          console.log("[UI] Away Mode preflight failed:", errors);
          setAwayModeIndicator(false);
          // Could show error toast here
        });

        // User returned modal removed - Away Mode controlled from Dashboard

        // Camera check listener - DISABLED in v2.1.0
        // Away Mode does NOT require camera access. This listener is kept
        // for backward compatibility but will always return false without
        // actually accessing the camera hardware.
        window.electronAPI.onAwayModeCheckCamera?.(async () => {
          console.log("[UI] Camera check requested (IGNORED - camera not needed for Away Mode)");
          // IMPORTANT: Do NOT call getUserMedia here!
          // Always return false - camera check is no longer needed for Away Mode.
          window.electronAPI.sendCameraCheckResult(false);
        });

        // DEBUG: Power blocker status - will show in DevTools console
        if (typeof window.electronAPI.onPowerBlockerStatus === 'function') {
          console.log('[UI] PowerBlocker listener registered');
          window.electronAPI.onPowerBlockerStatus((data) => {
          console.log(`[UI] ğŸ”‹ POWER BLOCKER: ${data.status} (id: ${data.id})`);
          if (data.status === 'STOPPED') {
            console.log('[UI] âœ… Power save blocker STOPPED - system CAN now sleep');
          } else if (data.status === 'STARTED') {
            console.log('[UI] âš¡ Power save blocker ACTIVE - system will NOT sleep');
          } else if (data.status === 'ALREADY_NULL') {
            console.log('[UI] â„¹ï¸ Power save blocker was already stopped');
          }
          });
        } else {
          console.warn('[UI] âš ï¸ onPowerBlockerStatus is MISSING on window.electronAPI (preload.js not updated / not loaded)');
        }
      }

      // User Returned Modal removed - Away Mode controlled manually from Dashboard

      // ============================================================
      // INIT
      // ============================================================
      setLanguage("en");
      document.getElementById("lang-en").addEventListener("click", () => setLanguage("en"));
      document.getElementById("lang-he").addEventListener("click", () => setLanguage("he"));
      codeInputs[0]?.focus();
    </script>
  </body>
</html>
